import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from surprise import Reader, Dataset, SVD, KNNBasic
from surprise.model_selection import cross_validate
import matplotlib.pyplot as plt
# Load data
data = pd.read_csv('movie_ratings.csv') # Load your data file (e.g., 'movie_ratings.csv')
# Data preparation
# The data should contain user_id, movie_id, and rating columns
# Verify that the data is in the expected format
print(data.head())
# Split data into training and testing sets
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)
# Define the reader and load the data into Surprise Dataset format
reader = Reader(rating_scale=(data['rating'].min(), data['rating'].max()))
train_dataset = Dataset.load_from_df(train_data[['user_id', 'movie_id', 'rating']], reader)
test_dataset = Dataset.load_from_df(test_data[['user_id', 'movie_id', 'rating']], reader)
# Use the SVD (Singular Value Decomposition) algorithm for collaborative filtering
algo = SVD()
# Train the model
trainset = train_dataset.build_full_trainset()
algo.fit(trainset)
# Evaluate the model on the test set
testset = test_dataset.build_full_trainset().build_testset()
predictions = algo.test(testset)
mse = mean_squared_error([pred.est for pred in predictions], [pred.r_ui for pred in predictions])
print(f"Mean Squared Error: {mse}")
# Use K-Nearest Neighbors (KNN) for collaborative filtering
knn_algo = KNNBasic()
# Train the KNN model
knn_algo.fit(trainset)
# Evaluate the KNN model
knn_predictions = knn_algo.test(testset)
knn_mse = mean_squared_error([pred.est for pred in knn_predictions], [pred.r_ui for pred in
knn_predictions])
print(f"KNN - Mean Squared Error: {knn_mse}")
# Choose the model with the best performance based on evaluation metrics
# Recommend top movies for a specific user
def recommend_movies(user_id, n=5):
# Get all movies in the dataset
all_movies = train_data['movie_id'].unique()
# Filter movies that the user has not rated yet
user_rated_movies = train_data[train_data['user_id'] == user_id]['movie_id'].values
unseen_movies = np.setdiff1d(all_movies, user_rated_movies)
# Predict ratings for unseen movies
predictions = []
for movie_id in unseen_movies:
predictions.append(algo.predict(user_id, movie_id))
# Sort predictions by estimated rating in descending order and return the top n movies
recommendations = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]
top_movies = [(pred.iid, pred.est) for pred in recommendations]
return top_movies
# Get top movie recommendations for a specific user
user_id = 1 # Replace with the user ID for whom you want to recommend movies
top_movies = recommend_movies(user_id, n=5)
print(f"Top movie recommendations for user {user_id}:")
for movie_id, est_rating in top_movies:
print(f"Movie ID: {movie_id}, Estimated Rating: {est_rating}")
# Optional: Plot the distribution of estimated ratings
est_ratings = [pred.est for pred in predictions]
plt.hist(est_ratings, bins=10)
plt.xlabel('Estimated Rating')
plt.ylabel('Frequency')
plt.title('Distribution of Estimated Ratings')
plt.show()
